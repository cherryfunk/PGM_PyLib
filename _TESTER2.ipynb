{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as it\n",
    "from PGM_PyLib.MRF import RMRFwO as mrf\n",
    "import requests\n",
    "import pandas as pd\n",
    "import contextlib\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate random probability distributions for bounding boxes\n",
    "def generate_random_probabilities(num_boxes, num_states):\n",
    "    \"\"\"\n",
    "    Generate random probability distributions for each bounding box.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_boxes: int, number of bounding boxes\n",
    "    - num_states: int, number of states (e.g., \"tree\", \"glass\", \"car\", \"cup\")\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (num_boxes, num_states), where each row is a\n",
    "      probability distribution over the states for a bounding box.\n",
    "    \"\"\"\n",
    "    probabilities = np.random.rand(num_boxes, num_states)  # Generate random values\n",
    "    probabilities /= probabilities.sum(axis=1, keepdims=True)  # Normalize each row to sum to 1\n",
    "    return probabilities\n",
    "\n",
    "# Generate the 4x4 relational probability matrix (for the 4 states)\n",
    "def generate_symmetric_matrix(n):\n",
    "    \"\"\"Generate an n x n symmetric matrix for 0-based indexing.\"\"\"\n",
    "    mat = np.random.rand(n, n)  # Generate random values\n",
    "    mat = (mat + mat.T) / 2  # Make the matrix symmetric\n",
    "    np.fill_diagonal(mat, 1)  # Fill the diagonal with 1s for self-relations\n",
    "    return mat\n",
    "\n",
    "# Define psi and Uf functions\n",
    "def psi(state_i, state_j):\n",
    "    \"\"\"\n",
    "    Return the probability of transitioning from state_i to state_j\n",
    "    based on the relational probability matrix (0-based indexing).\n",
    "    \"\"\"\n",
    "    return relational_probabilities[state_i, state_j]\n",
    "\n",
    "# Assuming relational_probabilities is global\n",
    "def Uf(rmrf, observation, row, col):\n",
    "    \"\"\"\n",
    "    Local energy function for a bounding box in a complete graph (3 rows, 1 column RMRF).\n",
    "    \n",
    "    This function calculates the energy based on the current state of the bounding box\n",
    "    and its relationships with all other bounding boxes (complete graph assumption).\n",
    "    Additionally, it considers n-tuples (n >= 3) by averaging the weights for all such tuples.\n",
    "    Observation probabilities are also factored into the energy calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    - rmrf: 2D numpy array, current RMRF matrix (3 rows, 1 column, states should be 0-based)\n",
    "    - observation: bounding box probability distributions\n",
    "    - row: int, row index (0-based, corresponding to the bounding box)\n",
    "    - col: int, column index (should always be 0 since it's a 1-column matrix)\n",
    "\n",
    "    Returns:\n",
    "    - float, the calculated energy for the bounding box at row `row`\n",
    "    \"\"\"\n",
    "    current_state = rmrf[row, col]  # Get the current state of the bounding box\n",
    "    energy = 0.0\n",
    "    \n",
    "    # 1. Factor in the observation (1-tuple) likelihood for the bounding box\n",
    "    obs_prob = observation[row][current_state]  # Probability for the current state\n",
    "    energy -= np.log(obs_prob)  # Add the energy contribution from the observation\n",
    "    \n",
    "    # 2. Calculate the pairwise (2-tuple) energy from the relationships with other bounding boxes (complete graph)\n",
    "    num_boxes = rmrf.shape[0]  # Number of bounding boxes (rows in rmrf)\n",
    "\n",
    "    for other_row in range(num_boxes):\n",
    "        if other_row != row:  # Avoid self-relations\n",
    "            other_state = rmrf[other_row, col]  # Get the state of the other bounding box\n",
    "            # Get the potential (weight) from the relational probability matrix\n",
    "            weight = relational_probabilities[current_state, other_state]\n",
    "            energy -= np.log(weight)  # Add the energy contribution from the relationship\n",
    "\n",
    "    # 3. Consider n-tuples (n >= 3) and calculate the average weight as basis for the energy\n",
    "    # Iterate over all possible n-tuples (where n >= 3)\n",
    "    for n in range(3, num_boxes + 1):  # Start from n=3, up to n=num_boxes\n",
    "        # Get all combinations of bounding boxes of size n\n",
    "        tuples = list(it.combinations(range(num_boxes), n))\n",
    "        \n",
    "        # For each n-tuple, calculate the average relational probability\n",
    "        for t in tuples:\n",
    "            # Extract the relational probabilities for all pairs in the tuple\n",
    "            pairwise_weights = [\n",
    "                relational_probabilities[rmrf[i, col], rmrf[j, col]]\n",
    "                for i, j in it.combinations(t, 2)\n",
    "            ]\n",
    "            \n",
    "            # Calculate the mean of the pairwise weights using NumPy\n",
    "            if pairwise_weights:  # Ensure there are weights to average\n",
    "                average_weight = np.mean(pairwise_weights)\n",
    "                energy -= np.log(average_weight)  # Subtract the energy from the average weight\n",
    "    \n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_energy(current_states, observation, relational_matrix):\n",
    "    \"\"\"\n",
    "    Global energy function for the entire RMRF in the current state (complete graph assumption).\n",
    "    \"\"\"\n",
    "\n",
    "    energy           = 0.0\n",
    "    num_vertices     = len(current_states) # Number of bounding boxes\n",
    "    pairwise_weights = relational_matrix[np.ix_(current_states, current_states)] # Compute the pairwise weights by indexing the relational_matrix\n",
    "    \n",
    "    # 1. Factor in the observation (1-tuple) likelihood for the bounding box\n",
    "    obs_probs    = observation[np.arange(num_vertices), current_states]  # Extract the probabilities for the current states\n",
    "    energy      -= np.sum(np.log(obs_probs)) # Sum the log probabilities and subtract from energy\n",
    "    \n",
    "    # 2. Consider 2-tuples and calculate the weight as basis for the energy\n",
    "    i_upper, j_upper = np.triu_indices(num_vertices, k=1)  # Get indices for all 2-tuples (upper triangle)\n",
    "    energy          -= np.sum(np.log(pairwise_weights[i_upper, j_upper]))  # Subtract log of all pairwise weights\n",
    "\n",
    "    # 3. Consider n-tuples (n >= 3) and calculate the average weight as basis for the energy\n",
    "    # Iterate over all possible n-tuples, starting from n=3\n",
    "    for n in range(3, num_vertices + 1):\n",
    "        # Get all n-tuples (combinations of vertices of size n)\n",
    "        tuples = list(it.combinations(range(num_vertices), n))\n",
    "        \n",
    "        # Collect pairwise weights for all tuples of this size n\n",
    "        all_pairwise_weights = []\n",
    "        \n",
    "        for t in tuples:\n",
    "            # Extract the pairwise weights for the current n-tuple (submatrix)\n",
    "            submatrix = pairwise_weights[np.ix_(t, t)]  # Submatrix for the current n-tuple\n",
    "            i, j = np.triu_indices(n, k=1)  # Indices for upper triangular part (pairwise combinations)\n",
    "            tuple_weights = submatrix[i, j]  # Pairwise weights for this n-tuple\n",
    "            \n",
    "            # Add the weights to the list of all pairwise weights for this n\n",
    "            all_pairwise_weights.extend(tuple_weights)\n",
    "        \n",
    "        # Calculate the mean over all pairwise weights across all n-tuples\n",
    "        if all_pairwise_weights:  # Ensure there are weights to average\n",
    "            average_weight = np.mean(all_pairwise_weights)\n",
    "            energy -= np.log(average_weight)  # Subtract log of the mean of all tuple weights\n",
    "    \n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.37262467 0.13818001 0.69311656]\n",
      " [0.37262467 1.         0.5142627  0.48602117]\n",
      " [0.13818001 0.5142627  1.         0.73740158]\n",
      " [0.69311656 0.48602117 0.73740158 1.        ]]\n",
      "[0 0 1] [1 2 2]\n",
      "[[1.         0.37262467 0.13818001]\n",
      " [0.37262467 1.         0.5142627 ]\n",
      " [0.13818001 0.5142627  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "current_states = np.array([0, 1, 2])  # Random initial current_states\n",
    "observation = bounding_box_probabilities\n",
    "energy = 0.0\n",
    "num_vertices = len(current_states)\n",
    "relational_matrix = relational_probabilities\n",
    "print(relational_probabilities)\n",
    "\n",
    "\n",
    "pairwise_weights = relational_matrix[np.ix_(current_states, current_states)] # Compute the pairwise weights by indexing the relational_matrix\n",
    "# Handle 2-tuples separately, where we directly subtract log of the weights\n",
    "i_upper, j_upper = np.triu_indices(num_vertices, k=1)  # Get indices for all 2-tuples (upper triangle)\n",
    "energy -= np.sum(np.log(pairwise_weights[i_upper, j_upper]))  # Subtract log of all pairwise weights\n",
    "\n",
    "print(i_upper, j_upper)\n",
    "print(pairwise_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMRF\n",
      " [[0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Random Relational Probability Matrix (ConceptNet):\n",
      "[[1.         0.37262467 0.13818001 0.69311656]\n",
      " [0.37262467 1.         0.5142627  0.48602117]\n",
      " [0.13818001 0.5142627  1.         0.73740158]\n",
      " [0.69311656 0.48602117 0.73740158 1.        ]]\n",
      "\n",
      "Random Bounding Box Probabilities (Computer Vision):\n",
      "[[0.29079279 0.07427418 0.20491863 0.4300144 ]\n",
      " [0.42070478 0.01251235 0.30446055 0.26232231]\n",
      " [0.40747266 0.15727423 0.28766843 0.14758468]] \n",
      "\n",
      "Succesfully finish, iteration: 0\n",
      "\n",
      "Final RMRF after inference (Bounding Box States):\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Define the states\n",
    "s = [0, 1, 2, 3]  # States corresponding to [\"tree\", \"glass\", \"car\", \"cup\"]\n",
    "\n",
    "# Initialize the RMRF as a vector of length 3 (one component for each bounding box)\n",
    "r = np.zeros((3, 1), dtype=int)  # Initial RMRF values (three rows, one column)\n",
    "print(\"Initial RMRF\\n\", r)\n",
    "\n",
    "# Assuming we have a 4x4 relational probability matrix for the 4 states (this should come from the ConceptNet)\n",
    "relational_probabilities = generate_symmetric_matrix(4)\n",
    "print(\"\\nRandom Relational Probability Matrix (ConceptNet):\")\n",
    "print(relational_probabilities)\n",
    "\n",
    "# Generate random probability distributions for 3 bounding boxes and 4 states (this should come from the Computer Vision observation)\n",
    "bounding_box_probabilities = generate_random_probabilities(num_boxes=3, num_states=4)\n",
    "print(\"\\nRandom Bounding Box Probabilities (Computer Vision):\")\n",
    "print(bounding_box_probabilities, \"\\n\")\n",
    "\n",
    "# Create an instance of RMRFwO and run inference\n",
    "mr = mrf(s, r, bounding_box_probabilities)  # Use the bounding box probabilities as the observation\n",
    "\n",
    "# Run inference using the Uf function\n",
    "result = mr.inference(Uf=Uf, maxIterations=100, Temp=1.0, tempReduction=1.0, optimal=\"MAP\")\n",
    "\n",
    "print(\"\\nFinal RMRF after inference (Bounding Box States):\")\n",
    "print(result)  # This will be a 3x1 matrix with the final state for each bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMRF\n",
      " [[0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Relational Probability Matrix (ConceptNet):\n",
      "[[1.   0.9  0.95 0.2 ]\n",
      " [0.9  1.   0.95 0.3 ]\n",
      " [0.95 0.95 1.   0.4 ]\n",
      " [0.2  0.3  0.4  1.  ]]\n",
      "\n",
      "Bounding Box Probabilities (Computer Vision):\n",
      "[[0.9  0.05 0.03 0.02]\n",
      " [0.1  0.8  0.05 0.05]\n",
      " [0.05 0.1  0.75 0.1 ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the states\n",
    "s = [0, 1, 2, 3]  # States corresponding to [\"tree\", \"glass\", \"car\", \"cup\"]\n",
    "\n",
    "# Initialize the RMRF as a vector of length 3 (one component for each bounding box)\n",
    "r = np.zeros((3, 1), dtype=int)  # Initial RMRF values (three rows, one column)\n",
    "print(\"Initial RMRF\\n\", r)\n",
    "\n",
    "# Assuming we have a 4x4 relational probability matrix for the 4 states (this should come from the ConceptNet)\n",
    "# Relational probability matrix (ConceptNet-like)\n",
    "relational_probabilities = np.array([\n",
    "    [1.0, 0.9, 0.95, 0.2],  # State 0 (\"tree\") is highly related to State 1 (\"glass\") and State 2 (\"car\")\n",
    "    [0.9, 1.0, 0.95, 0.3],  # State 1 (\"glass\") is highly related to State 0 (\"tree\") and State 2 (\"car\")\n",
    "    [0.95, 0.95, 1.0, 0.4], # State 2 (\"car\") is highly related to State 0 (\"tree\") and State 1 (\"glass\")\n",
    "    [0.2, 0.3, 0.4, 1.0]    # State 3 (\"cup\") is weakly related to other states\n",
    "])\n",
    "\n",
    "print(\"\\nRelational Probability Matrix (ConceptNet):\")\n",
    "print(relational_probabilities)\n",
    "\n",
    "# Bounding Box Probabilities (Computer Vision)\n",
    "# Strong preference for state 0 for bounding box 0, state 1 for bounding box 1, and state 2 for bounding box 2\n",
    "observation = np.array([\n",
    "    [0.9, 0.05, 0.03, 0.02],  # Bounding Box 0 (strongly prefers \"tree\")\n",
    "    [0.1, 0.8, 0.05, 0.05],   # Bounding Box 1 (strongly prefers \"glass\")\n",
    "    [0.05, 0.1, 0.75, 0.1]    # Bounding Box 2 (strongly prefers \"car\")\n",
    "])\n",
    "print(\"\\nBounding Box Probabilities (Computer Vision):\")\n",
    "print(observation, \"\\n\")\n",
    "\n",
    "# Create an instance of RMRFwO and run inference\n",
    "mr = mrf(s, r, observation)  # Use the bounding box probabilities as the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Assignment  Total Energy  Rank\n",
      "6   (0, 1, 2)      1.239059     1\n",
      "2   (0, 0, 2)      3.002506     2\n",
      "5   (0, 1, 1)      3.259510     3\n",
      "10  (0, 2, 2)      3.695653     4\n",
      "22  (1, 1, 2)      3.813436     5\n",
      "4   (0, 1, 0)      3.952657     6\n",
      "38  (2, 1, 2)      4.324261     7\n",
      "1   (0, 0, 1)      5.338951     8\n",
      "0   (0, 0, 0)      5.403678     9\n",
      "21  (1, 1, 1)      5.521461    10\n"
     ]
    }
   ],
   "source": [
    "# Calculate the energy for all possible assignments\n",
    "def calculate_all_assignments_energy():\n",
    "    # Generate all possible state assignments for 3 bounding boxes and 4 states\n",
    "    all_assignments = list(it.product([0, 1, 2, 3], repeat=3))\n",
    "\n",
    "    # Initialize results to store the energies for all assignments\n",
    "    results = []\n",
    "\n",
    "    # Iterate through all possible assignments\n",
    "    for assignment in all_assignments:\n",
    "        # Convert assignment to a 2D array to be compatible with Uf function\n",
    "        rmrf = np.array(assignment).reshape(-1, 1)\n",
    "\n",
    "        # Calculate the total energy for the current assignment\n",
    "        total_energy = 0.0\n",
    "        for row in range(rmrf.shape[0]):\n",
    "            total_energy += Uf(rmrf, observation, row, col=0)  # HALF THE WEIGHTS BECAUSE THEY ARE ADDED TWICE\n",
    "        \n",
    "        # Store the assignment and its total energy\n",
    "        results.append((assignment, total_energy))\n",
    "    \n",
    "    # Convert results to a DataFrame for easy visualization\n",
    "    df = pd.DataFrame(results, columns=[\"Assignment\", \"Total Energy\"])\n",
    "\n",
    "    # Add a new column 'Rank' that gives the order of the counts\n",
    "    df[\"Rank\"] = df[\"Total Energy\"].rank(method=\"min\").astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate energies for all assignments\n",
    "all_assignment_energies = calculate_all_assignments_energy()\n",
    "\n",
    "# Display the result in a sorted manner (ascending by energy)\n",
    "all_assignment_energies_sorted = all_assignment_energies.sort_values(by=\"Total Energy\")\n",
    "print(all_assignment_energies_sorted.head(10))  # Display the top results to check the minimum energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Result  Count  Percentage  Rank\n",
      "5  [0 1 2]   3263       32.63     1\n",
      "0  [0 0 0]   2245       22.45     2\n",
      "2  [0 0 2]   1791       17.91     3\n",
      "4  [0 1 1]   1377       13.77     4\n",
      "1  [0 0 1]    961        9.61     5\n",
      "3  [0 1 0]    363        3.63     6\n"
     ]
    }
   ],
   "source": [
    "# Run the inference n times and display the results for each run and the counts for each unique result\n",
    "n = 10000  # Number of inference runs\n",
    "results = []\n",
    "\n",
    "# Create a dummy stream to suppress print statements\n",
    "f = io.StringIO()\n",
    "\n",
    "for i in range(n):\n",
    "    # Create an instance of RMRFwO and run inference\n",
    "    mr = mrf(s, r, observation)  # Use the bounding box probabilities as the observation\n",
    "    \n",
    "    # Suppress the output of inference method\n",
    "    with contextlib.redirect_stdout(f):\n",
    "        result = mr.inference(Uf=Uf, maxIterations=100, Temp=1.0, tempReduction=1.0, optimal=\"MAP\")\n",
    "    \n",
    "    # Store the result\n",
    "    results.append(list(result.flatten()))  # Convert to a list of integers for proper comparison\n",
    "\n",
    "# Count the occurrences of each unique result\n",
    "unique_results, counts = np.unique(results, axis=0, return_counts=True)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "df_results = pd.DataFrame({\n",
    "    'Result': [str(res) for res in unique_results],  # Convert the result tuples to strings for better display\n",
    "    'Count': counts,\n",
    "    'Percentage': (counts / n) * 100\n",
    "})\n",
    "\n",
    "# Add a new column 'Rank' that gives the order of the counts\n",
    "df_results['Rank'] = df_results['Count'].rank(ascending=False, method='dense').astype(int)\n",
    "\n",
    "# Sort the results by count\n",
    "df_results = df_results.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 'AtLocation' edges retrieved for 'glass': 17\n",
      "a glass -> the cabinet (Weight: 4.0)\n",
      "a glass -> a window (Weight: 3.4641016151377544)\n",
      "a glass -> a kitchen (Weight: 2.82842712474619)\n",
      "a glass -> the table (Weight: 2.0)\n",
      "a glass -> a water cooler (Weight: 1.0)\n",
      "a glass -> a dishwasher (Weight: 1.0)\n",
      "a glass -> a hand (Weight: 1.0)\n",
      "a glass -> a sink (Weight: 1.0)\n",
      "a glass -> a cuboard (Weight: 1.0)\n",
      "a glass -> your kitchen cupboard (Weight: 1.0)\n",
      "a glass -> a (Weight: 1.0)\n",
      "a glass -> a dining room (Weight: 1.0)\n",
      "glass -> a street (Weight: 1.0)\n",
      "water -> a glass (Weight: 4.0)\n",
      "an overflow -> a glass (Weight: 1.0)\n",
      "ice -> a glass (Weight: 1.0)\n",
      "ice cubes -> a glass (Weight: 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Define the search endpoint for fetching edges with the 'AtLocation' relation\n",
    "search_url = 'http://api.conceptnet.io/query'\n",
    "\n",
    "# Function to search for edges with 'AtLocation' relation, including 'glass' as both start and end\n",
    "def get_atlocation_edges_both_directions(concept, max_limit=50):\n",
    "    params_start = {\n",
    "        'start': f'/c/en/{concept}',  # Fetch edges where 'glass' is the start\n",
    "        'rel': '/r/AtLocation',\n",
    "        'limit': max_limit\n",
    "    }\n",
    "    params_end = {\n",
    "        'end': f'/c/en/{concept}',    # Fetch edges where 'glass' is the end\n",
    "        'rel': '/r/AtLocation',\n",
    "        'limit': max_limit\n",
    "    }\n",
    "\n",
    "    # Fetch edges where 'glass' is the start\n",
    "    response_start = requests.get(search_url, params=params_start).json()\n",
    "    edges_start = response_start['edges']\n",
    "\n",
    "    # Fetch edges where 'glass' is the end\n",
    "    response_end = requests.get(search_url, params=params_end).json()\n",
    "    edges_end = response_end['edges']\n",
    "\n",
    "    # Combine both sets of edges\n",
    "    return edges_start + edges_end\n",
    "\n",
    "# Fetch 'AtLocation' edges for the concept \"glass\" with a limit\n",
    "atlocation_edges = get_atlocation_edges_both_directions('glass', max_limit=100000)\n",
    "\n",
    "# Print the number of 'AtLocation' edges retrieved\n",
    "print(f\"Total 'AtLocation' edges retrieved for 'glass': {len(atlocation_edges)}\")\n",
    "\n",
    "#Show all the weight and concepts for AtLocation of glas and show diretcion in a visual way\n",
    "for edge in atlocation_edges:\n",
    "    start = edge['start']['label'].split('/')[-1]\n",
    "    end = edge['end']['label'].split('/')[-1]\n",
    "    weight = edge['weight']\n",
    "    print(f\"{start} -> {end} (Weight: {weight})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tree   glass     car     cup\n",
      "tree   1.0000  0.5315  0.5450  0.4920\n",
      "glass  0.5315  1.0000  0.5365  0.6345\n",
      "car    0.5450  0.5365  1.0000  0.5180\n",
      "cup    0.4920  0.6345  0.5180  1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the list of concepts in the desired order\n",
    "concepts = [\"tree\", \"glass\", \"car\", \"cup\"]\n",
    "\n",
    "# Define the base URL for the ConceptNet relatedness API\n",
    "relatedness_url = 'http://api.conceptnet.io/relatedness'\n",
    "\n",
    "# Function to get the relatedness value between two concepts\n",
    "def get_relatedness(concept1, concept2):\n",
    "    params = {\n",
    "        'node1': f'/c/en/{concept1}',\n",
    "        'node2': f'/c/en/{concept2}'\n",
    "    }\n",
    "    response = requests.get(relatedness_url, params=params).json()\n",
    "    return response['value']\n",
    "\n",
    "# Initialize a 4x4 matrix to store the relatedness values\n",
    "relatedness_matrix = np.ones((4, 4))  # Start with an identity matrix (relatedness of 1 for the same concepts)\n",
    "\n",
    "# Create all concept pairs (excluding same concept pairs as they are 1.0 by default)\n",
    "concept_pairs = list(it.product(range(4), repeat=2))\n",
    "concept_pairs = [(i, j) for i, j in concept_pairs if i != j]\n",
    "\n",
    "# Fetch relatedness for each pair and populate the matrix\n",
    "for i, j in concept_pairs:\n",
    "    relatedness_matrix[i, j] = get_relatedness(concepts[i], concepts[j])\n",
    "\n",
    "# Rescale the relatedness values from [-1, 1] to [0, 1]\n",
    "rescaled_matrix = (relatedness_matrix + 1) / 2\n",
    "\n",
    "# Create a pandas DataFrame for better readability with the desired order\n",
    "relatedness_df = pd.DataFrame(rescaled_matrix, index=concepts, columns=concepts)\n",
    "\n",
    "# Display the rescaled 4x4 matrix\n",
    "print(relatedness_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
